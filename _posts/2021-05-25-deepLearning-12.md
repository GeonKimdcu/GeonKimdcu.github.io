---
layout: post
title: '[DeepLearning] CH04. 머신 러닝의 기본 요소(5)'
subtitle: 'deepLearning start'
categories: deeplearning
tags: deeplearning
comments: true
---
`케라스 창시자에게 배우는 딥러닝`을 기반으로 공부한 내용을 정리합니다.

<img src="/assets/img/dlcourse/book.jpeg" width="200" height="200">

## 4.5 보편적인 머신 러닝 작업 흐름

### 4.5.1 문제 정의와 데이터셋 수집
먼저 주어진 문제를 정의해야 합니다.

- 입력 데이터는 무엇인가요? 어떤 것을 예측하려고 하나요? 가용한 훈련 데이터가 있어야 어떤 것을 예측하도록 학습할 수 있습니다.<br>
예를 들어 영화 리뷰와 감성 레이블이 태깅되어 있어야 영화 리뷰의 감성 분류를 학습할 수 있습니다.

- 당면한 문제가 어떤 종류인가요? 이진 분류, 다중 분류, 스칼라 회귀, 벡터 회귀, 다중 레이블 다중 분류, 군집, 생성 또는 강화 학습 등. <br>
문제의 유형을 식별하면 모델의 구조와 손실 함수 등을 선택하는데 도움이 됩니다.

다음으로 주어진 입력으로 출력을 예측할 수 있다고 가설을 세웁니다. 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세웁니다.<br>
입력 X와 타깃 Y의 sample을 수집했다고 X에 Y를 예측하기에 충분한 정보가 있는 것은 아닙니다.

머신 러닝은 훈련 데이터에 있는 패턴을 기억하기 위해서만 사용한다는 것을 유념해야 합니다. **이미 보았던 것만 인식할 수 있습니다.** 

### 4.5.2 성공 지표 선택
성공의 지표가 모델이 최적화할 손실 함수를 선택하는 기준이 됩니다. <br>

클래스 분포가 균일한 분류 문제에서는 정확도와 [ROC AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=ko)가 일반적인 지표입니다.

클래스 분포가 균일하지 않은 문제에서는 [정밀도와 재현율](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=ko)을 사용할 수 있습니다. 

랭킹 문제나 다중 레이블 문제에서는 평균 정밀도를 사용할 수 있습니다.

### 4.5.3 평가 방법 선택
목표를 정했다면 현재의 진척 상황을 평가할 방법을 정해야 합니다.
- **홀드아웃 검증 세트 분리**: 데이터가 풍부할 때 사용합니다.
- **K-겹 교차 검증**: 홀드아웃 검증을 사용하기에 샘플의 수가 너무 적을 때 사용합니다.
- **반복 K-겹 교차 검증**: 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용합니다.

### 4.5.4 데이터 준비
무엇을 훈련할지와 무엇을 최적화할지, 그리고 어떻게 평가할지를 정했다면 거의 모델을 훈련시킬 준비가 되었습니다. <br>
하지만 먼저 머신 러닝 모델에 주입할 데이터를 구성해야 합니다. 이 모델을 심층 신경망이라고 가정합니다.

- 데이터는 텐서로 구성됩니다.
- 이 텐서에 있는 값은 일반적으로 작은 값으로 스케일 조정되어 있습니다. 예를 들어 [-1, 1]이나 [0, 1] 범위입니다.
- 특성마다 범위가 다르면(여러 종류의 값으로 이루어진 데이터라면) 정규화해야 합니다.
- 특성 공학을 수행할 수 있습니다. 특히 데이터가 적을 때 유용합니다.

입력 데이터와 타깃 데이터의 텐서가 준비되면 모델을 훈련시킬 수 있습니다.

### 4.5.5 기본보다 나은 모델 훈련하기
이 단계의 목표는 **통계적 검정력**(statistical power)을 달성하는 것입니다. 즉 아주 단순한 모델보다 나은 수준의 작은 모델을 개발합니다. <br>
예를 들어 MNIST 숫자 이미지 분류에선 0.1보다 높은 정확도를 내는 모델이 통계적 검정력을 가졌다고 할 수 있습니다.
-> 10개의 숫자 중 1개는 지목해야 하므로 0.1임

또 다른 예로 IMDB 이진분류에선 0.5보다 높은 정확도를 갖는 것입니다.

![img](/assets/img/dlcourse/capture01.png)

### 4.5.6 몸집 키우기: 과대적합 모델 구축
통계적 검정력을 가진 모델을 얻었다면 이제 모델이 충분히 성능을 내는지 질문해 보아야 합니다. <br>
주어진 문제를 적절히 모델링하기에 충분한 층과 파라미터가 있나요?

과소적합과 과대적합 사이, 즉 과소용량과 과대용량의 경계에 적절히 위치한 모델이 이상적입니다. 이 경계가 어디에 위치하는지 찾기 위해서는 먼저 지나쳐 보아야 합니다. <br>
얼마나 큰 모델을 만들어야 하는지 알기 위해서는 과대적합된 모델을 만들어야 합니다.

1. 층을 추가합니다.
2. 층의 크기를 키웁니다.
3. 더 많은 에포크 동안 훈련합니다.

관심 대상인 훈련과 검증 지표는 물론 항상 훈련 손실과 검증 손실을 모니터링해야합니다. 검증 데이터에서 모델 성능이 감소하기 시작했을 때 과대적합에 도달한 것입니다.

### 4.5.7 모델 규제와 하이퍼파라미터 튜닝
반복적으로 모델을 수정하고 훈련하고 검증 데이터에서 평가합니다.(이떄 테스트 데이터를 사용하지 않습니다). 그리고 다시 수정하고 가능한 좋은 모델을 얻을 때까지 반복합니다.
- 드롭아웃을 추가합니다.
- 층을 추가하거나 제거해서 다른 구조를 시도해 봅니다.
- L1이나 L2 또는 두 가지 모두 추가합니다.
- 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도해 봅니다(층의 유닛 수나 옵티마이저의 학습률 등).
- 선택적으로 특성 공학을 시도해 봅니다. 새로운 특성을 추가하거나 유용하지 않을 것 같은 특성을 제거합니다.

다음 사항을 유념해야합니다. <br>
검증 과정에서 얻은 피드백을 사용하여 모델을 튜닝할 때마다 검증 과정에 대한 정보를 모델에 누설하고 있다는 것입니다. 몇 번만 반복하는 것은 큰 문제가 되지 않습니다. <br>
하지만 많이 반복하게 되면 결국 모델이 검증 과정에 과대적합될 것입니다(모델이 검증데이터에서 전혀 훈련되지 않는데도 말입니다). 이는 검증 과정의 신뢰도를 감소시킵니다.

만족할 만한 모델 설정을 얻었다면 가용한 모든 데이터(훈련 데이터와 검증 데이터)를 사용해서 제품에 투입할 최종 모델을 훈련시킵니다.<br>
그리고 마지막에 딱 한 번 테스트 세트에서 평가합니다. 테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 검증 데이터에 과대적합된 것입니다. <br>
이런 경우, 반복 K-겹 교차 검증과 같은 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋습니다.

## 4.6 요약
- 주어진 문제와 훈련할 데이터를 정의합니다. 데이터를 수집하고 필요하면 레이블을 태깅합니다.
- 성공을 어떻게 측정할지 선택해야합니다. 검증 데이터에서 모니터링할 지표를 선택해야 합니다.
- 평가 방법을 결정해야 합니다. 홀드아웃 검증, K-겹 교차 검증 등.  검증에 사용해야 할 데이터의 양은 어떤지 파악합니다.
- 단순한 랜덤 선택 모델보다 나은 통계적 검정력이 있는 첫 번째 모델을 만듭니다.
- 과대적합된 모델을 만듭니다.
- 검증 데이터의 성능에 기초하여 모델에 규제를 적용하고 하이퍼파라미터를 튜닝합니다. 머신 러닝 연구의 대부분은 이 단계에 집중됩니다.


<br><br>

## Reference
1. 케라스 창시자에게 배우는 딥러닝
2. https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=ko
3. https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=ko